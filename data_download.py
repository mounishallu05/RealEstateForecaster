import os
import pandas as pd
import requests
from tqdm import tqdm
import zipfile
from io import BytesIO
import numpy as np

def download_dataset():
    """
    Downloads the USA house pricing dataset.
    For this example, we'll use a publicly available housing dataset from Kaggle.
    In a real application, you might need to use Kaggle API or other methods.
    
    For demonstration purposes, we'll fallback to creating synthetic data if download fails.
    """
    data_dir = 'data'
    
    # Create data directory if it doesn't exist
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        
    try:
        print("Attempting to download housing dataset...")
        # In a real application, you would use something like:
        # url = "https://storage.googleapis.com/kaggle-data-sets/18911/24106/compressed/house-prices.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256..."
        
        # For demonstration, we'll generate synthetic data instead
        raise Exception("Using synthetic data instead of actual download")
        
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        # Extract zip file
        with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:
            zip_ref.extractall(data_dir)
            
        print(f"Dataset downloaded and extracted to {data_dir}")
        
    except Exception as e:
        print(f"Download failed or skipped: {e}")
        print("Generating synthetic housing data instead...")
        
        # Generate synthetic housing data
        np.random.seed(42)
        n_samples = 5000
        
        # Generate features
        zipcode_base = np.random.randint(10000, 99999, n_samples)
        sqft = np.random.normal(2000, 700, n_samples).astype(int)
        sqft = np.clip(sqft, 500, 5000)
        bedrooms = np.random.choice([1, 2, 3, 4, 5, 6], n_samples, p=[0.05, 0.1, 0.35, 0.3, 0.15, 0.05])
        bathrooms = np.random.choice([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5], n_samples)
        year_built = np.random.randint(1900, 2023, n_samples)
        lot_size = np.random.normal(10000, 5000, n_samples).astype(int)
        lot_size = np.clip(lot_size, 2000, 50000)
        
        # States and their average price factors
        states = ['CA', 'NY', 'TX', 'FL', 'WA', 'CO', 'IL', 'GA', 'NC', 'OH', 
                  'PA', 'MA', 'AZ', 'NJ', 'MI', 'VA', 'WI', 'MN', 'OR', 'MD']
        
        state_price_factors = {
            'CA': 1.8, 'NY': 1.7, 'TX': 0.9, 'FL': 1.1, 'WA': 1.3, 
            'CO': 1.2, 'IL': 1.0, 'GA': 0.9, 'NC': 0.85, 'OH': 0.7,
            'PA': 0.8, 'MA': 1.5, 'AZ': 1.0, 'NJ': 1.4, 'MI': 0.6,
            'VA': 1.1, 'WI': 0.8, 'MN': 0.9, 'OR': 1.2, 'MD': 1.1
        }
        
        # Assign states
        state = np.random.choice(states, n_samples)
        
        # Generate prices based on features with some noise
        base_price = 150000
        price = base_price + \
                sqft * 100 + \
                bedrooms * 20000 + \
                bathrooms * 15000 + \
                (2023 - year_built) * (-500) + \
                lot_size * 0.5
        
        # Apply state pricing factor
        for i, s in enumerate(state):
            price[i] *= state_price_factors[s]
        
        # Add some random noise (Â±15%)
        price *= np.random.normal(1, 0.15, n_samples)
        price = price.astype(int)
        
        # Create DataFrame
        df = pd.DataFrame({
            'zipcode': zipcode_base,
            'state': state,
            'sqft': sqft,
            'bedrooms': bedrooms,
            'bathrooms': bathrooms,
            'year_built': year_built,
            'lot_size': lot_size,
            'price': price
        })
        
        # Add some categorical features
        df['has_garage'] = np.random.choice([0, 1], n_samples, p=[0.2, 0.8])
        df['has_pool'] = np.random.choice([0, 1], n_samples, p=[0.8, 0.2])
        df['house_type'] = np.random.choice(['Single Family', 'Townhouse', 'Condo'], n_samples, p=[0.65, 0.25, 0.1])
        df['neighborhood_quality'] = np.random.choice(['Low', 'Medium', 'High', 'Very High'], n_samples, p=[0.1, 0.4, 0.4, 0.1])
        
        # Save to CSV
        df.to_csv(os.path.join(data_dir, 'housing_data.csv'), index=False)
        print(f"Synthetic housing dataset saved to {os.path.join(data_dir, 'housing_data.csv')}")
        
        # Create a small test set as well
        test_sample = np.random.choice(range(n_samples), size=int(n_samples * 0.2), replace=False)
        df_test = df.iloc[test_sample].copy()
        df_train = df.drop(test_sample).copy()
        
        df_test.to_csv(os.path.join(data_dir, 'housing_data_test.csv'), index=False)
        df_train.to_csv(os.path.join(data_dir, 'housing_data_train.csv'), index=False)
        
        print(f"Split data into training ({len(df_train)} samples) and test ({len(df_test)} samples) sets")
        
        return df

if __name__ == "__main__":
    download_dataset() 